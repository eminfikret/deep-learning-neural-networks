{
 "cells": [
  {
   "cell_type": "code",
   "id": "initial_id",
   "metadata": {
    "collapsed": true,
    "ExecuteTime": {
     "end_time": "2025-10-25T17:59:54.686992Z",
     "start_time": "2025-10-25T17:58:51.643010Z"
    }
   },
   "source": [
    "# 03_experiments_mlp.ipynb applying imbalance tricks during experiments\n",
    "\n",
    "# speed and gpu\n",
    "import os\n",
    "os.environ['XLA_FLAGS'] = '--xla_gpu_cuda_data_dir=/opt/cuda'\n",
    "import json, numpy as np, matplotlib.pyplot as plt, tensorflow as tf\n",
    "from tensorflow import keras\n",
    "from tensorflow.keras import mixed_precision\n",
    "from sklearn.utils.class_weight import compute_class_weight\n",
    "from sklearn.metrics import f1_score, confusion_matrix, classification_report, ConfusionMatrixDisplay\n",
    "\n",
    "tf.config.optimizer.set_jit(True)\n",
    "try: tf.config.experimental.enable_tensor_float_32_execution(True)\n",
    "except: pass\n",
    "mixed_precision.set_global_policy('mixed_float16')\n",
    "gpus = tf.config.list_physical_devices('GPU')\n",
    "if gpus:\n",
    "    try: tf.config.experimental.set_memory_growth(gpus[0], True)\n",
    "    except: pass\n",
    "\n",
    "# load meta and data\n",
    "with open('../artifacts/metadata.json') as f: meta = json.load(f)\n",
    "num_classes = len(meta['label_classes'])\n",
    "X_train = np.load('../artifacts/X_train.npy')\n",
    "X_val   = np.load('../artifacts/X_val.npy')\n",
    "y_train = np.load('../artifacts/y_train.npy')\n",
    "y_val   = np.load('../artifacts/y_val.npy')\n",
    "\n",
    "# one hot labels\n",
    "y_train_oh = keras.utils.to_categorical(y_train, num_classes)\n",
    "y_val_oh   = keras.utils.to_categorical(y_val,   num_classes)\n",
    "\n",
    "# scale with saved stats or compute here\n",
    "X_mean = np.load('../artifacts/X_mean.npy') if os.path.exists('../artifacts/X_mean.npy') else X_train.mean(0)\n",
    "X_std  = np.load('../artifacts/X_std.npy')  if os.path.exists('../artifacts/X_std.npy')  else X_train.std(0) + 1e-8\n",
    "X_train_s = (X_train - X_mean) / X_std\n",
    "X_val_s   = (X_val   - X_mean) / X_std\n",
    "np.save('../artifacts/X_mean.npy', X_mean)\n",
    "np.save('../artifacts/X_std.npy',  X_std)\n",
    "\n",
    "# cast to float16 for speed\n",
    "X_train_s = X_train_s.astype('float16', copy=False)\n",
    "X_val_s   = X_val_s.astype('float16', copy=False)\n",
    "\n",
    "# imbalance handling on train only\n",
    "# 1 undersample huge classes a bit\n",
    "rng = np.random.default_rng(42)\n",
    "max_keep = 10000\n",
    "keep_idx = []\n",
    "for c in range(num_classes):\n",
    "    idx = np.where(y_train == c)[0]\n",
    "    if len(idx) > max_keep:\n",
    "        idx = rng.choice(idx, max_keep, replace=False)\n",
    "    keep_idx.append(idx)\n",
    "keep_idx = np.concatenate(keep_idx)\n",
    "X_train_us = X_train_s[keep_idx]\n",
    "y_train_us = y_train[keep_idx]\n",
    "\n",
    "# 2 oversample rare classes up to target\n",
    "target_per_class = 5000\n",
    "xs, ys = [], []\n",
    "for c in range(num_classes):\n",
    "    m = (y_train_us == c)\n",
    "    x_c = X_train_us[m]\n",
    "    y_c = keras.utils.to_categorical(y_train_us[m], num_classes)\n",
    "    n = len(x_c)\n",
    "    if n > 0 and n < target_per_class:\n",
    "        add = rng.integers(0, n, target_per_class - n)\n",
    "        x_c = np.concatenate([x_c, x_c[add]], 0)\n",
    "        y_c = np.concatenate([y_c, y_c[add]], 0)\n",
    "    xs.append(x_c); ys.append(y_c)\n",
    "X_train_bal = np.concatenate(xs, 0)\n",
    "y_train_bal = np.concatenate(ys, 0)\n",
    "\n",
    "# shuffle\n",
    "perm = rng.permutation(len(X_train_bal))\n",
    "X_train_bal = X_train_bal[perm]\n",
    "y_train_bal = y_train_bal[perm]\n",
    "\n",
    "# 3 class weights on the balanced labels too\n",
    "y_train_bal_labels = np.argmax(y_train_bal, 1)\n",
    "classes = np.unique(y_train_bal_labels)\n",
    "weights = compute_class_weight('balanced', classes=classes, y=y_train_bal_labels)\n",
    "class_weights = {int(c): float(w) for c, w in zip(classes, weights)}\n",
    "\n",
    "# datasets\n",
    "BATCH = 1024\n",
    "train_ds = tf.data.Dataset.from_tensor_slices((X_train_bal, y_train_bal)).cache().shuffle(10000).batch(BATCH).prefetch(tf.data.AUTOTUNE)\n",
    "val_ds   = tf.data.Dataset.from_tensor_slices((X_val_s,   y_val_oh)).cache().batch(BATCH).prefetch(tf.data.AUTOTUNE)\n",
    "\n",
    "os.makedirs('../artifacts/experiments', exist_ok=True)\n",
    "\n",
    "# configs vary layers width act and dropout\n",
    "configs = [\n",
    "    {'name':'relu_1x64_do0',     'layers':[64],          'act':'relu',    'dropout':0.0},\n",
    "    {'name':'relu_2x64_do03',    'layers':[64,64],       'act':'relu',    'dropout':0.3},\n",
    "    {'name':'relu_3x128_do03',   'layers':[128,128,128], 'act':'relu',    'dropout':0.3},\n",
    "    {'name':'tanh_1x128_do0',    'layers':[128],         'act':'tanh',    'dropout':0.0},\n",
    "    {'name':'tanh_2x128_do02',   'layers':[128,128],     'act':'tanh',    'dropout':0.2},\n",
    "    {'name':'sigmoid_2x64_do02', 'layers':[64,64],       'act':'sigmoid', 'dropout':0.2},\n",
    "    {'name':'relu_1x256_do02',   'layers':[256],         'act':'relu',    'dropout':0.2},\n",
    "    {'name':'tanh_3x256_do03',   'layers':[256,256,256], 'act':'tanh',    'dropout':0.3},\n",
    "]\n",
    "\n",
    "# model builder\n",
    "def build_model(input_dim, cfg, num_classes):\n",
    "    inp = keras.Input(shape=(input_dim,))\n",
    "    x = inp\n",
    "    for u in cfg['layers']:\n",
    "        x = keras.layers.Dense(u, activation=cfg['act'])(x)\n",
    "        if cfg['dropout'] > 0.0:\n",
    "            x = keras.layers.Dropout(cfg['dropout'])(x)\n",
    "    out = keras.layers.Dense(num_classes, activation='softmax', dtype='float32')(x)\n",
    "    m = keras.Model(inp, out)\n",
    "    opt = keras.optimizers.legacy.Adam(1e-3)\n",
    "    m.compile(optimizer=opt, loss='categorical_crossentropy', metrics=['accuracy'])\n",
    "    return m\n",
    "\n",
    "# train and log\n",
    "best_name = None\n",
    "best_metric = -1.0\n",
    "results = []\n",
    "\n",
    "for i, cfg in enumerate(configs, 1):\n",
    "    print(f'[{i}/{len(configs)}] {cfg[\"name\"]}')\n",
    "    model = build_model(X_train_s.shape[1], cfg, num_classes)\n",
    "    hist = model.fit(\n",
    "        train_ds,\n",
    "        validation_data=val_ds,\n",
    "        epochs=20,\n",
    "        verbose=1,\n",
    "        class_weight=class_weights\n",
    "    )\n",
    "\n",
    "    # plots\n",
    "    acc_path  = f\"../artifacts/experiments/{cfg['name']}_acc.png\"\n",
    "    loss_path = f\"../artifacts/experiments/{cfg['name']}_loss.png\"\n",
    "    plt.figure(); plt.plot(hist.history['accuracy']); plt.plot(hist.history['val_accuracy']); plt.legend(['train','val']); plt.title(cfg['name']+' acc'); plt.xlabel('epoch'); plt.ylabel('accuracy'); plt.savefig(acc_path, dpi=150); plt.close()\n",
    "    plt.figure(); plt.plot(hist.history['loss']); plt.plot(hist.history['val_loss']); plt.legend(['train','val']); plt.title(cfg['name']+' loss'); plt.xlabel('epoch'); plt.ylabel('loss'); plt.savefig(loss_path, dpi=150); plt.close()\n",
    "\n",
    "    # val metrics macro f1\n",
    "    yv_pred = model.predict(X_val_s, batch_size=4096).argmax(1)\n",
    "    macro_f1 = f1_score(y_val, yv_pred, average='macro')\n",
    "    val_acc  = float(np.mean(yv_pred == y_val))\n",
    "\n",
    "    # save confusion matrix for val\n",
    "    cm = confusion_matrix(y_val, yv_pred)\n",
    "    disp = ConfusionMatrixDisplay(cm, display_labels=meta['label_classes'])\n",
    "    disp.plot(xticks_rotation=90, cmap='Blues')\n",
    "    plt.title(cfg['name']+' val confusion')\n",
    "    plt.tight_layout()\n",
    "    plt.savefig(f\"../artifacts/experiments/{cfg['name']}_val_confusion.png\", dpi=150)\n",
    "    plt.close()\n",
    "\n",
    "    # classification report to txt\n",
    "    rep = classification_report(y_val, yv_pred, target_names=meta['label_classes'])\n",
    "    with open(f\"../artifacts/experiments/{cfg['name']}_val_report.txt\",'w') as f: f.write(rep)\n",
    "\n",
    "    results.append({'name':cfg['name'],'layers':cfg['layers'],'act':cfg['act'],'dropout':cfg['dropout'],'val_acc':val_acc,'macro_f1':float(macro_f1)})\n",
    "\n",
    "    # choose best by macro f1 to be fair to rare classes\n",
    "    if macro_f1 > best_metric:\n",
    "        best_metric = macro_f1\n",
    "        best_name = cfg['name']\n",
    "        model.save('../artifacts/best_so_far.keras')\n",
    "        with open('../artifacts/best_so_far_name.txt','w') as f: f.write(best_name)\n",
    "\n",
    "# save summary\n",
    "with open('../artifacts/experiments/results.json','w') as f: json.dump(results, f, indent=2)\n",
    "print('best by macro f1', best_name, best_metric)\n",
    "for r in sorted(results, key=lambda x: x['macro_f1'], reverse=True):\n",
    "    print(r)\n"
   ],
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[1/8] relu_1x64_do0\n",
      "Epoch 1/20\n",
      "69/69 [==============================] - 1s 6ms/step - loss: 2.2219 - accuracy: 0.1665 - val_loss: 2.2260 - val_accuracy: 0.1358\n",
      "Epoch 2/20\n",
      "69/69 [==============================] - 1s 7ms/step - loss: 1.9701 - accuracy: 0.2479 - val_loss: 2.1117 - val_accuracy: 0.1898\n",
      "Epoch 3/20\n",
      "69/69 [==============================] - 0s 3ms/step - loss: 1.7789 - accuracy: 0.3017 - val_loss: 2.0028 - val_accuracy: 0.2346\n",
      "Epoch 4/20\n",
      "69/69 [==============================] - 0s 3ms/step - loss: 1.6391 - accuracy: 0.3342 - val_loss: 1.9162 - val_accuracy: 0.2662\n",
      "Epoch 5/20\n",
      "69/69 [==============================] - 0s 3ms/step - loss: 1.5426 - accuracy: 0.3669 - val_loss: 1.8538 - val_accuracy: 0.2895\n",
      "Epoch 6/20\n",
      "69/69 [==============================] - 0s 3ms/step - loss: 1.4740 - accuracy: 0.3860 - val_loss: 1.8229 - val_accuracy: 0.2981\n",
      "Epoch 7/20\n",
      "69/69 [==============================] - 0s 4ms/step - loss: 1.4230 - accuracy: 0.3943 - val_loss: 1.7878 - val_accuracy: 0.3131\n",
      "Epoch 8/20\n",
      "69/69 [==============================] - 0s 3ms/step - loss: 1.3824 - accuracy: 0.4026 - val_loss: 1.7623 - val_accuracy: 0.3238\n",
      "Epoch 9/20\n",
      "69/69 [==============================] - 0s 3ms/step - loss: 1.3498 - accuracy: 0.4128 - val_loss: 1.7449 - val_accuracy: 0.3269\n",
      "Epoch 10/20\n",
      "69/69 [==============================] - 0s 3ms/step - loss: 1.3228 - accuracy: 0.4164 - val_loss: 1.7336 - val_accuracy: 0.3274\n",
      "Epoch 11/20\n",
      "69/69 [==============================] - 0s 3ms/step - loss: 1.3008 - accuracy: 0.4193 - val_loss: 1.7173 - val_accuracy: 0.3336\n",
      "Epoch 12/20\n",
      "69/69 [==============================] - 0s 3ms/step - loss: 1.2827 - accuracy: 0.4226 - val_loss: 1.7138 - val_accuracy: 0.3283\n",
      "Epoch 13/20\n",
      "69/69 [==============================] - 0s 3ms/step - loss: 1.2678 - accuracy: 0.4266 - val_loss: 1.6982 - val_accuracy: 0.3348\n",
      "Epoch 14/20\n",
      "69/69 [==============================] - 0s 3ms/step - loss: 1.2544 - accuracy: 0.4276 - val_loss: 1.6786 - val_accuracy: 0.3426\n",
      "Epoch 15/20\n",
      "69/69 [==============================] - 0s 3ms/step - loss: 1.2431 - accuracy: 0.4312 - val_loss: 1.6680 - val_accuracy: 0.3420\n",
      "Epoch 16/20\n",
      "69/69 [==============================] - 0s 3ms/step - loss: 1.2327 - accuracy: 0.4335 - val_loss: 1.6677 - val_accuracy: 0.3454\n",
      "Epoch 17/20\n",
      "69/69 [==============================] - 0s 3ms/step - loss: 1.2234 - accuracy: 0.4351 - val_loss: 1.6711 - val_accuracy: 0.3353\n",
      "Epoch 18/20\n",
      "69/69 [==============================] - 0s 3ms/step - loss: 1.2146 - accuracy: 0.4377 - val_loss: 1.6587 - val_accuracy: 0.3430\n",
      "Epoch 19/20\n",
      "69/69 [==============================] - 0s 3ms/step - loss: 1.2066 - accuracy: 0.4394 - val_loss: 1.6474 - val_accuracy: 0.3450\n",
      "Epoch 20/20\n",
      "69/69 [==============================] - 0s 3ms/step - loss: 1.1990 - accuracy: 0.4403 - val_loss: 1.6323 - val_accuracy: 0.3577\n",
      "38/38 [==============================] - 0s 743us/step\n",
      "[2/8] relu_2x64_do03\n",
      "Epoch 1/20\n",
      "69/69 [==============================] - 1s 6ms/step - loss: 2.2326 - accuracy: 0.1564 - val_loss: 2.2276 - val_accuracy: 0.1507\n",
      "Epoch 2/20\n",
      "69/69 [==============================] - 1s 8ms/step - loss: 1.9515 - accuracy: 0.2351 - val_loss: 2.0474 - val_accuracy: 0.2279\n",
      "Epoch 3/20\n",
      "69/69 [==============================] - 0s 3ms/step - loss: 1.7330 - accuracy: 0.2883 - val_loss: 1.9144 - val_accuracy: 0.2819\n",
      "Epoch 4/20\n",
      "69/69 [==============================] - 0s 3ms/step - loss: 1.5985 - accuracy: 0.3218 - val_loss: 1.8225 - val_accuracy: 0.3314\n",
      "Epoch 5/20\n",
      "69/69 [==============================] - 0s 3ms/step - loss: 1.4989 - accuracy: 0.3489 - val_loss: 1.7665 - val_accuracy: 0.3609\n",
      "Epoch 6/20\n",
      "69/69 [==============================] - 0s 3ms/step - loss: 1.4344 - accuracy: 0.3624 - val_loss: 1.7351 - val_accuracy: 0.3622\n",
      "Epoch 7/20\n",
      "69/69 [==============================] - 0s 3ms/step - loss: 1.3910 - accuracy: 0.3734 - val_loss: 1.7207 - val_accuracy: 0.3716\n",
      "Epoch 8/20\n",
      "69/69 [==============================] - 0s 3ms/step - loss: 1.3583 - accuracy: 0.3817 - val_loss: 1.7039 - val_accuracy: 0.3810\n",
      "Epoch 9/20\n",
      "69/69 [==============================] - 0s 3ms/step - loss: 1.3320 - accuracy: 0.3913 - val_loss: 1.6685 - val_accuracy: 0.4086\n",
      "Epoch 10/20\n",
      "69/69 [==============================] - 0s 3ms/step - loss: 1.3173 - accuracy: 0.3956 - val_loss: 1.6538 - val_accuracy: 0.4059\n",
      "Epoch 11/20\n",
      "69/69 [==============================] - 0s 3ms/step - loss: 1.3013 - accuracy: 0.4010 - val_loss: 1.6405 - val_accuracy: 0.4201\n",
      "Epoch 12/20\n",
      "69/69 [==============================] - 0s 3ms/step - loss: 1.2863 - accuracy: 0.4028 - val_loss: 1.6420 - val_accuracy: 0.4129\n",
      "Epoch 13/20\n",
      "69/69 [==============================] - 0s 3ms/step - loss: 1.2753 - accuracy: 0.4060 - val_loss: 1.6245 - val_accuracy: 0.4159\n",
      "Epoch 14/20\n",
      "69/69 [==============================] - 0s 3ms/step - loss: 1.2670 - accuracy: 0.4090 - val_loss: 1.6169 - val_accuracy: 0.4215\n",
      "Epoch 15/20\n",
      "69/69 [==============================] - 0s 3ms/step - loss: 1.2530 - accuracy: 0.4156 - val_loss: 1.6078 - val_accuracy: 0.4305\n",
      "Epoch 16/20\n",
      "69/69 [==============================] - 0s 3ms/step - loss: 1.2462 - accuracy: 0.4200 - val_loss: 1.5776 - val_accuracy: 0.4348\n",
      "Epoch 17/20\n",
      "69/69 [==============================] - 0s 3ms/step - loss: 1.2339 - accuracy: 0.4216 - val_loss: 1.5835 - val_accuracy: 0.4433\n",
      "Epoch 18/20\n",
      "69/69 [==============================] - 0s 3ms/step - loss: 1.2298 - accuracy: 0.4217 - val_loss: 1.5701 - val_accuracy: 0.4407\n",
      "Epoch 19/20\n",
      "69/69 [==============================] - 0s 3ms/step - loss: 1.2247 - accuracy: 0.4244 - val_loss: 1.5773 - val_accuracy: 0.4553\n",
      "Epoch 20/20\n",
      "69/69 [==============================] - 0s 3ms/step - loss: 1.2130 - accuracy: 0.4272 - val_loss: 1.5561 - val_accuracy: 0.4444\n",
      "38/38 [==============================] - 0s 754us/step\n",
      "[3/8] relu_3x128_do03\n",
      "Epoch 1/20\n",
      "69/69 [==============================] - 1s 7ms/step - loss: 2.0025 - accuracy: 0.2134 - val_loss: 1.8997 - val_accuracy: 0.2863\n",
      "Epoch 2/20\n",
      "69/69 [==============================] - 1s 11ms/step - loss: 1.5631 - accuracy: 0.3293 - val_loss: 1.7699 - val_accuracy: 0.3664\n",
      "Epoch 3/20\n",
      "69/69 [==============================] - 0s 3ms/step - loss: 1.4013 - accuracy: 0.3669 - val_loss: 1.6563 - val_accuracy: 0.4154\n",
      "Epoch 4/20\n",
      "69/69 [==============================] - 0s 3ms/step - loss: 1.3238 - accuracy: 0.3869 - val_loss: 1.6388 - val_accuracy: 0.4326\n",
      "Epoch 5/20\n",
      "69/69 [==============================] - 0s 3ms/step - loss: 1.2822 - accuracy: 0.4020 - val_loss: 1.6055 - val_accuracy: 0.4434\n",
      "Epoch 6/20\n",
      "69/69 [==============================] - 0s 3ms/step - loss: 1.2510 - accuracy: 0.4141 - val_loss: 1.5629 - val_accuracy: 0.4606\n",
      "Epoch 7/20\n",
      "69/69 [==============================] - 0s 3ms/step - loss: 1.2258 - accuracy: 0.4216 - val_loss: 1.5528 - val_accuracy: 0.4547\n",
      "Epoch 8/20\n",
      "69/69 [==============================] - 0s 3ms/step - loss: 1.2005 - accuracy: 0.4303 - val_loss: 1.5246 - val_accuracy: 0.4661\n",
      "Epoch 9/20\n",
      "69/69 [==============================] - 0s 3ms/step - loss: 1.1810 - accuracy: 0.4373 - val_loss: 1.5321 - val_accuracy: 0.4501\n",
      "Epoch 10/20\n",
      "69/69 [==============================] - 0s 3ms/step - loss: 1.1590 - accuracy: 0.4453 - val_loss: 1.5310 - val_accuracy: 0.4459\n",
      "Epoch 11/20\n",
      "69/69 [==============================] - 0s 3ms/step - loss: 1.1437 - accuracy: 0.4537 - val_loss: 1.5372 - val_accuracy: 0.4539\n",
      "Epoch 12/20\n",
      "69/69 [==============================] - 0s 3ms/step - loss: 1.1222 - accuracy: 0.4593 - val_loss: 1.4896 - val_accuracy: 0.4606\n",
      "Epoch 13/20\n",
      "69/69 [==============================] - 0s 3ms/step - loss: 1.1060 - accuracy: 0.4640 - val_loss: 1.4515 - val_accuracy: 0.4636\n",
      "Epoch 14/20\n",
      "69/69 [==============================] - 0s 3ms/step - loss: 1.0875 - accuracy: 0.4704 - val_loss: 1.5024 - val_accuracy: 0.4555\n",
      "Epoch 15/20\n",
      "69/69 [==============================] - 0s 3ms/step - loss: 1.0726 - accuracy: 0.4778 - val_loss: 1.4874 - val_accuracy: 0.4584\n",
      "Epoch 16/20\n",
      "69/69 [==============================] - 0s 3ms/step - loss: 1.0549 - accuracy: 0.4836 - val_loss: 1.4442 - val_accuracy: 0.4772\n",
      "Epoch 17/20\n",
      "69/69 [==============================] - 0s 3ms/step - loss: 1.0384 - accuracy: 0.4900 - val_loss: 1.4465 - val_accuracy: 0.4741\n",
      "Epoch 18/20\n",
      "69/69 [==============================] - 0s 3ms/step - loss: 1.0243 - accuracy: 0.4951 - val_loss: 1.4553 - val_accuracy: 0.4777\n",
      "Epoch 19/20\n",
      "69/69 [==============================] - 0s 3ms/step - loss: 1.0130 - accuracy: 0.4984 - val_loss: 1.4570 - val_accuracy: 0.4758\n",
      "Epoch 20/20\n",
      "69/69 [==============================] - 0s 3ms/step - loss: 0.9985 - accuracy: 0.5031 - val_loss: 1.4310 - val_accuracy: 0.4879\n",
      "38/38 [==============================] - 0s 787us/step\n",
      "[4/8] tanh_1x128_do0\n",
      "Epoch 1/20\n",
      "69/69 [==============================] - 1s 5ms/step - loss: 2.2346 - accuracy: 0.1464 - val_loss: 2.2937 - val_accuracy: 0.0182\n",
      "Epoch 2/20\n",
      "69/69 [==============================] - 0s 7ms/step - loss: 2.1655 - accuracy: 0.1563 - val_loss: 2.2565 - val_accuracy: 0.0281\n",
      "Epoch 3/20\n",
      "69/69 [==============================] - 0s 3ms/step - loss: 2.1141 - accuracy: 0.1743 - val_loss: 2.2358 - val_accuracy: 0.0354\n",
      "Epoch 4/20\n",
      "69/69 [==============================] - 0s 3ms/step - loss: 2.0454 - accuracy: 0.2013 - val_loss: 2.2042 - val_accuracy: 0.0659\n",
      "Epoch 5/20\n",
      "69/69 [==============================] - 0s 3ms/step - loss: 1.9727 - accuracy: 0.2233 - val_loss: 2.1839 - val_accuracy: 0.0722\n",
      "Epoch 6/20\n",
      "69/69 [==============================] - 0s 3ms/step - loss: 1.8970 - accuracy: 0.2495 - val_loss: 2.1448 - val_accuracy: 0.1033\n",
      "Epoch 7/20\n",
      "69/69 [==============================] - 0s 3ms/step - loss: 1.8186 - accuracy: 0.2770 - val_loss: 2.1194 - val_accuracy: 0.1180\n",
      "Epoch 8/20\n",
      "69/69 [==============================] - 0s 3ms/step - loss: 1.7443 - accuracy: 0.2956 - val_loss: 2.0598 - val_accuracy: 0.1898\n",
      "Epoch 9/20\n",
      "69/69 [==============================] - 0s 3ms/step - loss: 1.6803 - accuracy: 0.3150 - val_loss: 2.0186 - val_accuracy: 0.2187\n",
      "Epoch 10/20\n",
      "69/69 [==============================] - 0s 3ms/step - loss: 1.6277 - accuracy: 0.3264 - val_loss: 1.9814 - val_accuracy: 0.2407\n",
      "Epoch 11/20\n",
      "69/69 [==============================] - 0s 3ms/step - loss: 1.5836 - accuracy: 0.3365 - val_loss: 1.9502 - val_accuracy: 0.2638\n",
      "Epoch 12/20\n",
      "69/69 [==============================] - 0s 3ms/step - loss: 1.5437 - accuracy: 0.3532 - val_loss: 1.9416 - val_accuracy: 0.2545\n",
      "Epoch 13/20\n",
      "69/69 [==============================] - 0s 3ms/step - loss: 1.5068 - accuracy: 0.3636 - val_loss: 1.9298 - val_accuracy: 0.2671\n",
      "Epoch 14/20\n",
      "69/69 [==============================] - 0s 3ms/step - loss: 1.4713 - accuracy: 0.3726 - val_loss: 1.8743 - val_accuracy: 0.2934\n",
      "Epoch 15/20\n",
      "69/69 [==============================] - 0s 4ms/step - loss: 1.4372 - accuracy: 0.3785 - val_loss: 1.8636 - val_accuracy: 0.2944\n",
      "Epoch 16/20\n",
      "69/69 [==============================] - 0s 3ms/step - loss: 1.4051 - accuracy: 0.3879 - val_loss: 1.8558 - val_accuracy: 0.2855\n",
      "Epoch 17/20\n",
      "69/69 [==============================] - 0s 4ms/step - loss: 1.3747 - accuracy: 0.3974 - val_loss: 1.8311 - val_accuracy: 0.2968\n",
      "Epoch 18/20\n",
      "69/69 [==============================] - 0s 3ms/step - loss: 1.3471 - accuracy: 0.4056 - val_loss: 1.8021 - val_accuracy: 0.3100\n",
      "Epoch 19/20\n",
      "69/69 [==============================] - 0s 4ms/step - loss: 1.3216 - accuracy: 0.4159 - val_loss: 1.7756 - val_accuracy: 0.3088\n",
      "Epoch 20/20\n",
      "69/69 [==============================] - 0s 3ms/step - loss: 1.2984 - accuracy: 0.4207 - val_loss: 1.7315 - val_accuracy: 0.3286\n",
      "38/38 [==============================] - 0s 899us/step\n",
      "[5/8] tanh_2x128_do02\n",
      "Epoch 1/20\n",
      "69/69 [==============================] - 1s 6ms/step - loss: 2.2395 - accuracy: 0.1414 - val_loss: 2.2720 - val_accuracy: 0.0245\n",
      "Epoch 2/20\n",
      "69/69 [==============================] - 1s 11ms/step - loss: 2.1415 - accuracy: 0.1720 - val_loss: 2.2158 - val_accuracy: 0.0809\n",
      "Epoch 3/20\n",
      "69/69 [==============================] - 0s 4ms/step - loss: 1.9953 - accuracy: 0.2166 - val_loss: 2.1261 - val_accuracy: 0.1577\n",
      "Epoch 4/20\n",
      "69/69 [==============================] - 0s 4ms/step - loss: 1.8087 - accuracy: 0.2704 - val_loss: 2.0144 - val_accuracy: 0.2251\n",
      "Epoch 5/20\n",
      "69/69 [==============================] - 0s 3ms/step - loss: 1.6710 - accuracy: 0.3060 - val_loss: 1.9317 - val_accuracy: 0.2576\n",
      "Epoch 6/20\n",
      "69/69 [==============================] - 0s 3ms/step - loss: 1.5804 - accuracy: 0.3272 - val_loss: 1.8807 - val_accuracy: 0.2903\n",
      "Epoch 7/20\n",
      "69/69 [==============================] - 0s 3ms/step - loss: 1.5062 - accuracy: 0.3480 - val_loss: 1.8280 - val_accuracy: 0.2981\n",
      "Epoch 8/20\n",
      "69/69 [==============================] - 0s 4ms/step - loss: 1.4530 - accuracy: 0.3625 - val_loss: 1.7695 - val_accuracy: 0.3316\n",
      "Epoch 9/20\n",
      "69/69 [==============================] - 0s 3ms/step - loss: 1.3983 - accuracy: 0.3777 - val_loss: 1.7542 - val_accuracy: 0.3415\n",
      "Epoch 10/20\n",
      "69/69 [==============================] - 0s 4ms/step - loss: 1.3654 - accuracy: 0.3862 - val_loss: 1.7550 - val_accuracy: 0.3285\n",
      "Epoch 11/20\n",
      "69/69 [==============================] - 0s 4ms/step - loss: 1.3341 - accuracy: 0.3959 - val_loss: 1.7081 - val_accuracy: 0.3525\n",
      "Epoch 12/20\n",
      "69/69 [==============================] - 0s 5ms/step - loss: 1.3102 - accuracy: 0.4004 - val_loss: 1.6767 - val_accuracy: 0.3655\n",
      "Epoch 13/20\n",
      "69/69 [==============================] - 0s 4ms/step - loss: 1.2927 - accuracy: 0.4072 - val_loss: 1.6784 - val_accuracy: 0.3695\n",
      "Epoch 14/20\n",
      "69/69 [==============================] - 0s 4ms/step - loss: 1.2696 - accuracy: 0.4145 - val_loss: 1.6236 - val_accuracy: 0.3894\n",
      "Epoch 15/20\n",
      "69/69 [==============================] - 0s 4ms/step - loss: 1.2558 - accuracy: 0.4184 - val_loss: 1.6308 - val_accuracy: 0.3879\n",
      "Epoch 16/20\n",
      "69/69 [==============================] - 0s 4ms/step - loss: 1.2467 - accuracy: 0.4203 - val_loss: 1.6179 - val_accuracy: 0.3767\n",
      "Epoch 17/20\n",
      "69/69 [==============================] - 0s 4ms/step - loss: 1.2323 - accuracy: 0.4240 - val_loss: 1.5956 - val_accuracy: 0.3932\n",
      "Epoch 18/20\n",
      "69/69 [==============================] - 0s 5ms/step - loss: 1.2214 - accuracy: 0.4279 - val_loss: 1.5706 - val_accuracy: 0.4153\n",
      "Epoch 19/20\n",
      "69/69 [==============================] - 0s 5ms/step - loss: 1.2103 - accuracy: 0.4322 - val_loss: 1.5944 - val_accuracy: 0.3950\n",
      "Epoch 20/20\n",
      "69/69 [==============================] - 0s 5ms/step - loss: 1.1994 - accuracy: 0.4346 - val_loss: 1.5560 - val_accuracy: 0.4112\n",
      "38/38 [==============================] - 0s 901us/step\n",
      "[6/8] sigmoid_2x64_do02\n",
      "Epoch 1/20\n",
      "69/69 [==============================] - 2s 7ms/step - loss: 2.3643 - accuracy: 0.1046 - val_loss: 2.2752 - val_accuracy: 0.1272\n",
      "Epoch 2/20\n",
      "69/69 [==============================] - 1s 12ms/step - loss: 2.2828 - accuracy: 0.1286 - val_loss: 2.2612 - val_accuracy: 0.0990\n",
      "Epoch 3/20\n",
      "69/69 [==============================] - 0s 4ms/step - loss: 2.2456 - accuracy: 0.1372 - val_loss: 2.2686 - val_accuracy: 0.0496\n",
      "Epoch 4/20\n",
      "69/69 [==============================] - 0s 4ms/step - loss: 2.2225 - accuracy: 0.1393 - val_loss: 2.2483 - val_accuracy: 0.0692\n",
      "Epoch 5/20\n",
      "69/69 [==============================] - 0s 4ms/step - loss: 2.2039 - accuracy: 0.1438 - val_loss: 2.2561 - val_accuracy: 0.0859\n",
      "Epoch 6/20\n",
      "69/69 [==============================] - 0s 4ms/step - loss: 2.1824 - accuracy: 0.1488 - val_loss: 2.2461 - val_accuracy: 0.1206\n",
      "Epoch 7/20\n",
      "69/69 [==============================] - 0s 4ms/step - loss: 2.1554 - accuracy: 0.1583 - val_loss: 2.2267 - val_accuracy: 0.1975\n",
      "Epoch 8/20\n",
      "69/69 [==============================] - 0s 5ms/step - loss: 2.1221 - accuracy: 0.1728 - val_loss: 2.1800 - val_accuracy: 0.2752\n",
      "Epoch 9/20\n",
      "69/69 [==============================] - 0s 4ms/step - loss: 2.0847 - accuracy: 0.1888 - val_loss: 2.1415 - val_accuracy: 0.2869\n",
      "Epoch 10/20\n",
      "69/69 [==============================] - 0s 4ms/step - loss: 2.0466 - accuracy: 0.2074 - val_loss: 2.1412 - val_accuracy: 0.2778\n",
      "Epoch 11/20\n",
      "69/69 [==============================] - 0s 4ms/step - loss: 2.0072 - accuracy: 0.2185 - val_loss: 2.0944 - val_accuracy: 0.2889\n",
      "Epoch 12/20\n",
      "69/69 [==============================] - 0s 4ms/step - loss: 1.9683 - accuracy: 0.2318 - val_loss: 2.0679 - val_accuracy: 0.2880\n",
      "Epoch 13/20\n",
      "69/69 [==============================] - 0s 4ms/step - loss: 1.9314 - accuracy: 0.2431 - val_loss: 2.0626 - val_accuracy: 0.2853\n",
      "Epoch 14/20\n",
      "69/69 [==============================] - 0s 4ms/step - loss: 1.8953 - accuracy: 0.2546 - val_loss: 2.0329 - val_accuracy: 0.2921\n",
      "Epoch 15/20\n",
      "69/69 [==============================] - 0s 4ms/step - loss: 1.8664 - accuracy: 0.2614 - val_loss: 2.0308 - val_accuracy: 0.2917\n",
      "Epoch 16/20\n",
      "69/69 [==============================] - 0s 4ms/step - loss: 1.8427 - accuracy: 0.2659 - val_loss: 2.0090 - val_accuracy: 0.3016\n",
      "Epoch 17/20\n",
      "69/69 [==============================] - 0s 3ms/step - loss: 1.8200 - accuracy: 0.2722 - val_loss: 2.0143 - val_accuracy: 0.2985\n",
      "Epoch 18/20\n",
      "69/69 [==============================] - 0s 3ms/step - loss: 1.7988 - accuracy: 0.2750 - val_loss: 2.0119 - val_accuracy: 0.2935\n",
      "Epoch 19/20\n",
      "69/69 [==============================] - 0s 4ms/step - loss: 1.7837 - accuracy: 0.2785 - val_loss: 1.9914 - val_accuracy: 0.3082\n",
      "Epoch 20/20\n",
      "69/69 [==============================] - 0s 4ms/step - loss: 1.7661 - accuracy: 0.2825 - val_loss: 1.9670 - val_accuracy: 0.3182\n",
      "38/38 [==============================] - 0s 1ms/step\n",
      "[7/8] relu_1x256_do02\n",
      "Epoch 1/20\n",
      "69/69 [==============================] - 1s 6ms/step - loss: 2.0727 - accuracy: 0.2121 - val_loss: 2.1029 - val_accuracy: 0.2058\n",
      "Epoch 2/20\n",
      "69/69 [==============================] - 1s 8ms/step - loss: 1.7128 - accuracy: 0.3223 - val_loss: 1.8918 - val_accuracy: 0.3041\n",
      "Epoch 3/20\n",
      "69/69 [==============================] - 0s 3ms/step - loss: 1.5163 - accuracy: 0.3753 - val_loss: 1.7843 - val_accuracy: 0.3395\n",
      "Epoch 4/20\n",
      "69/69 [==============================] - 0s 3ms/step - loss: 1.4059 - accuracy: 0.3991 - val_loss: 1.7269 - val_accuracy: 0.3505\n",
      "Epoch 5/20\n",
      "69/69 [==============================] - 0s 3ms/step - loss: 1.3426 - accuracy: 0.4097 - val_loss: 1.6936 - val_accuracy: 0.3597\n",
      "Epoch 6/20\n",
      "69/69 [==============================] - 0s 4ms/step - loss: 1.3010 - accuracy: 0.4161 - val_loss: 1.6481 - val_accuracy: 0.3717\n",
      "Epoch 7/20\n",
      "69/69 [==============================] - 0s 3ms/step - loss: 1.2727 - accuracy: 0.4213 - val_loss: 1.6353 - val_accuracy: 0.3779\n",
      "Epoch 8/20\n",
      "69/69 [==============================] - 0s 3ms/step - loss: 1.2520 - accuracy: 0.4264 - val_loss: 1.6574 - val_accuracy: 0.3590\n",
      "Epoch 9/20\n",
      "69/69 [==============================] - 0s 3ms/step - loss: 1.2337 - accuracy: 0.4325 - val_loss: 1.6401 - val_accuracy: 0.3687\n",
      "Epoch 10/20\n",
      "69/69 [==============================] - 0s 3ms/step - loss: 1.2222 - accuracy: 0.4322 - val_loss: 1.6402 - val_accuracy: 0.3637\n",
      "Epoch 11/20\n",
      "69/69 [==============================] - 0s 3ms/step - loss: 1.2071 - accuracy: 0.4399 - val_loss: 1.6219 - val_accuracy: 0.3765\n",
      "Epoch 12/20\n",
      "69/69 [==============================] - 0s 3ms/step - loss: 1.1956 - accuracy: 0.4436 - val_loss: 1.6081 - val_accuracy: 0.3734\n",
      "Epoch 13/20\n",
      "69/69 [==============================] - 0s 3ms/step - loss: 1.1871 - accuracy: 0.4448 - val_loss: 1.6081 - val_accuracy: 0.3816\n",
      "Epoch 14/20\n",
      "69/69 [==============================] - 0s 3ms/step - loss: 1.1778 - accuracy: 0.4472 - val_loss: 1.6149 - val_accuracy: 0.3733\n",
      "Epoch 15/20\n",
      "69/69 [==============================] - 0s 3ms/step - loss: 1.1693 - accuracy: 0.4515 - val_loss: 1.6197 - val_accuracy: 0.3682\n",
      "Epoch 16/20\n",
      "69/69 [==============================] - 0s 3ms/step - loss: 1.1624 - accuracy: 0.4512 - val_loss: 1.5666 - val_accuracy: 0.3960\n",
      "Epoch 17/20\n",
      "69/69 [==============================] - 0s 4ms/step - loss: 1.1553 - accuracy: 0.4532 - val_loss: 1.5910 - val_accuracy: 0.3782\n",
      "Epoch 18/20\n",
      "69/69 [==============================] - 0s 3ms/step - loss: 1.1483 - accuracy: 0.4579 - val_loss: 1.5666 - val_accuracy: 0.3893\n",
      "Epoch 19/20\n",
      "69/69 [==============================] - 0s 3ms/step - loss: 1.1423 - accuracy: 0.4589 - val_loss: 1.5420 - val_accuracy: 0.4025\n",
      "Epoch 20/20\n",
      "69/69 [==============================] - 0s 3ms/step - loss: 1.1398 - accuracy: 0.4602 - val_loss: 1.5298 - val_accuracy: 0.4052\n",
      "38/38 [==============================] - 0s 859us/step\n",
      "[8/8] tanh_3x256_do03\n",
      "Epoch 1/20\n",
      "69/69 [==============================] - 1s 8ms/step - loss: 2.2503 - accuracy: 0.1440 - val_loss: 2.2398 - val_accuracy: 0.0783\n",
      "Epoch 2/20\n",
      "69/69 [==============================] - 1s 11ms/step - loss: 2.1212 - accuracy: 0.1783 - val_loss: 2.1838 - val_accuracy: 0.1061\n",
      "Epoch 3/20\n",
      "69/69 [==============================] - 0s 4ms/step - loss: 1.8833 - accuracy: 0.2413 - val_loss: 2.0362 - val_accuracy: 0.1978\n",
      "Epoch 4/20\n",
      "69/69 [==============================] - 0s 4ms/step - loss: 1.6619 - accuracy: 0.3035 - val_loss: 1.9371 - val_accuracy: 0.2178\n",
      "Epoch 5/20\n",
      "69/69 [==============================] - 0s 4ms/step - loss: 1.4854 - accuracy: 0.3498 - val_loss: 1.7816 - val_accuracy: 0.2879\n",
      "Epoch 6/20\n",
      "69/69 [==============================] - 0s 4ms/step - loss: 1.3811 - accuracy: 0.3792 - val_loss: 1.7456 - val_accuracy: 0.3224\n",
      "Epoch 7/20\n",
      "69/69 [==============================] - 0s 4ms/step - loss: 1.3239 - accuracy: 0.3949 - val_loss: 1.7077 - val_accuracy: 0.3436\n",
      "Epoch 8/20\n",
      "69/69 [==============================] - 0s 4ms/step - loss: 1.2814 - accuracy: 0.4055 - val_loss: 1.7235 - val_accuracy: 0.3358\n",
      "Epoch 9/20\n",
      "69/69 [==============================] - 0s 4ms/step - loss: 1.2518 - accuracy: 0.4155 - val_loss: 1.6240 - val_accuracy: 0.3757\n",
      "Epoch 10/20\n",
      "69/69 [==============================] - 0s 4ms/step - loss: 1.2292 - accuracy: 0.4226 - val_loss: 1.6287 - val_accuracy: 0.3630\n",
      "Epoch 11/20\n",
      "69/69 [==============================] - 0s 4ms/step - loss: 1.2031 - accuracy: 0.4332 - val_loss: 1.5889 - val_accuracy: 0.3888\n",
      "Epoch 12/20\n",
      "69/69 [==============================] - 0s 5ms/step - loss: 1.1828 - accuracy: 0.4366 - val_loss: 1.5746 - val_accuracy: 0.3936\n",
      "Epoch 13/20\n",
      "69/69 [==============================] - 0s 4ms/step - loss: 1.1588 - accuracy: 0.4468 - val_loss: 1.5667 - val_accuracy: 0.3894\n",
      "Epoch 14/20\n",
      "69/69 [==============================] - 0s 4ms/step - loss: 1.1426 - accuracy: 0.4533 - val_loss: 1.5106 - val_accuracy: 0.4048\n",
      "Epoch 15/20\n",
      "69/69 [==============================] - 0s 5ms/step - loss: 1.1252 - accuracy: 0.4580 - val_loss: 1.4932 - val_accuracy: 0.4233\n",
      "Epoch 16/20\n",
      "69/69 [==============================] - 0s 4ms/step - loss: 1.1024 - accuracy: 0.4683 - val_loss: 1.4788 - val_accuracy: 0.4193\n",
      "Epoch 17/20\n",
      "69/69 [==============================] - 0s 4ms/step - loss: 1.0853 - accuracy: 0.4755 - val_loss: 1.4180 - val_accuracy: 0.4489\n",
      "Epoch 18/20\n",
      "69/69 [==============================] - 0s 4ms/step - loss: 1.0630 - accuracy: 0.4826 - val_loss: 1.4111 - val_accuracy: 0.4494\n",
      "Epoch 19/20\n",
      "69/69 [==============================] - 0s 4ms/step - loss: 1.0453 - accuracy: 0.4914 - val_loss: 1.3953 - val_accuracy: 0.4504\n",
      "Epoch 20/20\n",
      "69/69 [==============================] - 0s 4ms/step - loss: 1.0321 - accuracy: 0.4960 - val_loss: 1.3973 - val_accuracy: 0.4362\n",
      "38/38 [==============================] - 0s 2ms/step\n",
      "best by macro f1 relu_3x128_do03 0.29813944943987297\n",
      "{'name': 'relu_3x128_do03', 'layers': [128, 128, 128], 'act': 'relu', 'dropout': 0.3, 'val_acc': 0.48790869270480264, 'macro_f1': 0.29813944943987297}\n",
      "{'name': 'relu_2x64_do03', 'layers': [64, 64], 'act': 'relu', 'dropout': 0.3, 'val_acc': 0.4443799864420921, 'macro_f1': 0.209409009123433}\n",
      "{'name': 'relu_1x256_do02', 'layers': [256], 'act': 'relu', 'dropout': 0.2, 'val_acc': 0.40522500912551496, 'macro_f1': 0.1947416612585122}\n",
      "{'name': 'tanh_3x256_do03', 'layers': [256, 256, 256], 'act': 'tanh', 'dropout': 0.3, 'val_acc': 0.43626479637065235, 'macro_f1': 0.18526118814410747}\n",
      "{'name': 'tanh_2x128_do02', 'layers': [128, 128], 'act': 'tanh', 'dropout': 0.2, 'val_acc': 0.4112413307608072, 'macro_f1': 0.13532529941009144}\n",
      "{'name': 'relu_1x64_do0', 'layers': [64], 'act': 'relu', 'dropout': 0.0, 'val_acc': 0.35769411273921886, 'macro_f1': 0.11934421480731186}\n",
      "{'name': 'tanh_1x128_do0', 'layers': [128], 'act': 'tanh', 'dropout': 0.0, 'val_acc': 0.3286097929811754, 'macro_f1': 0.10054331354345676}\n",
      "{'name': 'sigmoid_2x64_do02', 'layers': [64, 64], 'act': 'sigmoid', 'dropout': 0.2, 'val_acc': 0.3182132241747927, 'macro_f1': 0.0751189419912163}\n"
     ]
    }
   ],
   "execution_count": 4
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
